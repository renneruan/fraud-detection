{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento\n",
    "\n",
    "Nesta etapa do projeto iremos utilizar das informações coletadas na etapa de EDA para tratarmos nossas features visando uma melhor aplicação ao modelo. Trazendo nossos resultados do EDA, temos:\n",
    "\n",
    "- Exclusão das variáveis `score_8` e `produto`\n",
    "- Há variáveis discretas dentre as numéricas\n",
    "- Podemos aplicar a transformação log nas variávels `score_3` e `valor_compra`\n",
    "- Podemos aplicar a transformação cúbica ao `score_6`\n",
    "- A variável `pais` pode ser agrupada em continentes\n",
    "- Podemos transformar a variável `data_compra` em hora do dia e dia da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pycountry_convert as pc\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>pais</th>\n",
       "      <th>score_7</th>\n",
       "      <th>produto</th>\n",
       "      <th>categoria_produto</th>\n",
       "      <th>score_8</th>\n",
       "      <th>score_9</th>\n",
       "      <th>score_10</th>\n",
       "      <th>entrega_doc_1</th>\n",
       "      <th>entrega_doc_2</th>\n",
       "      <th>entrega_doc_3</th>\n",
       "      <th>data_compra</th>\n",
       "      <th>valor_compra</th>\n",
       "      <th>score_fraude_modelo</th>\n",
       "      <th>fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>94436.24</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>5</td>\n",
       "      <td>Máquininha Corta Barba Cabelo Peito Perna Pelo...</td>\n",
       "      <td>cat_8d714cd</td>\n",
       "      <td>0.883598</td>\n",
       "      <td>240.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-27 11:51:16</td>\n",
       "      <td>5.64</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>9258.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>Avental Descartavel Manga Longa  - 50 Un. Tnt ...</td>\n",
       "      <td>cat_64b574b</td>\n",
       "      <td>0.376019</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-04-15 19:58:08</td>\n",
       "      <td>124.71</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>242549.09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>AR</td>\n",
       "      <td>23</td>\n",
       "      <td>Bicicleta Mountain Fire Bird Rodado 29 Alumini...</td>\n",
       "      <td>cat_e9110c5</td>\n",
       "      <td>0.516368</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-25 18:13:38</td>\n",
       "      <td>339.32</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>18923.90</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.482385</td>\n",
       "      <td>18.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>23</td>\n",
       "      <td>Caneta Delineador Carimbo Olho Gatinho Longo 2...</td>\n",
       "      <td>cat_d06e653</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-04-16 16:03:10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>5728.68</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>2</td>\n",
       "      <td>Resident Evil Operation Raccoon City Ps3</td>\n",
       "      <td>cat_6c4cfdc</td>\n",
       "      <td>0.855798</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-04-02 10:24:45</td>\n",
       "      <td>3.53</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_1  score_2    score_3  score_4   score_5  score_6 pais  score_7  \\\n",
       "0        4   0.7685   94436.24     20.0  0.444828      1.0   BR        5   \n",
       "1        4   0.7550    9258.50      1.0  0.000000     33.0   BR        0   \n",
       "2        4   0.7455  242549.09      3.0  0.000000     19.0   AR       23   \n",
       "3        4   0.7631   18923.90     50.0  0.482385     18.0   BR       23   \n",
       "4        2   0.7315    5728.68     15.0  0.000000      1.0   BR        2   \n",
       "\n",
       "                                             produto categoria_produto  \\\n",
       "0  Máquininha Corta Barba Cabelo Peito Perna Pelo...       cat_8d714cd   \n",
       "1  Avental Descartavel Manga Longa  - 50 Un. Tnt ...       cat_64b574b   \n",
       "2  Bicicleta Mountain Fire Bird Rodado 29 Alumini...       cat_e9110c5   \n",
       "3  Caneta Delineador Carimbo Olho Gatinho Longo 2...       cat_d06e653   \n",
       "4           Resident Evil Operation Raccoon City Ps3       cat_6c4cfdc   \n",
       "\n",
       "    score_8  score_9  score_10  entrega_doc_1 entrega_doc_2 entrega_doc_3  \\\n",
       "0  0.883598    240.0     102.0              1           NaN             N   \n",
       "1  0.376019   4008.0       0.0              1             Y             N   \n",
       "2  0.516368   1779.0      77.0              1           NaN             N   \n",
       "3  0.154036   1704.0    1147.0              1           NaN             Y   \n",
       "4  0.855798   1025.0     150.0              1           NaN             N   \n",
       "\n",
       "           data_compra  valor_compra  score_fraude_modelo  fraude  \n",
       "0  2020-03-27 11:51:16          5.64                   66       0  \n",
       "1  2020-04-15 19:58:08        124.71                   72       0  \n",
       "2  2020-03-25 18:13:38        339.32                   95       0  \n",
       "3  2020-04-16 16:03:10          3.54                    2       0  \n",
       "4  2020-04-02 10:24:45          3.53                   76       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/dados.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos dividir os dados da amostra em treino e teste antes de qualquer processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"fraude\", axis=1)\n",
    "y = df[\"fraude\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos construir as etapas de pré processamento como classes para serem aplicadas a um Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=[]):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumn(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        return X.drop(self.cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentsProcessor(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        X_new[self.cols] = X_new[self.cols].fillna(\"N\")\n",
    "        X_new[self.cols] = (X_new[self.cols] == \"Y\").astype(int)\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateProcessor(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        date = pd.to_datetime(X_new[\"data_compra\"])\n",
    "\n",
    "        X_new[\"hora_compra\"] = date.dt.hour\n",
    "        X_new[\"dia_compra\"] = date.dt.dayofweek\n",
    "\n",
    "        X_new = X_new.drop(\"data_compra\", axis=1)\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoderProcessor(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        X_encoded = pd.get_dummies(X, columns=self.cols, drop_first=True, dtype=int)\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputeValuesProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, discrete_cols=[], continuous_cols=[]):\n",
    "        self.discrete_cols = discrete_cols\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.numerical_imputer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\n",
    "                    \"discrete\",\n",
    "                    SimpleImputer(strategy=\"most_frequent\"),\n",
    "                    self.discrete_cols,\n",
    "                ),\n",
    "                (\"continuous\", SimpleImputer(strategy=\"mean\"), self.continuous_cols),\n",
    "            ],\n",
    "            remainder=\"passthrough\",\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.numerical_imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X_transformed = self.numerical_imputer.transform(X)\n",
    "        X_transformed = pd.DataFrame(X_transformed, columns=self._get_column_names(X))\n",
    "        return X_transformed\n",
    "\n",
    "    def _get_column_names(self, X):\n",
    "\n",
    "        transformed_columns = (\n",
    "            self.discrete_cols\n",
    "            + self.continuous_cols\n",
    "            + [\n",
    "                col\n",
    "                for col in X.columns\n",
    "                if col not in self.discrete_cols + self.continuous_cols\n",
    "            ]\n",
    "        )\n",
    "        return transformed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformColumns(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "\n",
    "        print(X_new[\"valor_compra\"].dtype)\n",
    "        X_new[\"log_score_3\"] = np.log1p(X_new[\"score_3\"].astype(float))\n",
    "        X_new[\"log_valor_compra\"] = np.log1p(X_new[\"valor_compra\"].astype(float))\n",
    "        X_new[\"cbrt_score_6\"] = np.cbrt(X_new[\"score_6\"].astype(float))\n",
    "\n",
    "        X_new = X_new.drop([\"score_3\", \"valor_compra\", \"score_6\"], axis=1)\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryProcessor(CustomProcessor):\n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        X_new[\"pais\"] = X_new[\"pais\"].fillna(X_new[\"pais\"].mode()[0])\n",
    "\n",
    "        X_new[\"continente\"] = X_new[\"pais\"].apply(\n",
    "            lambda x: pc.country_alpha2_to_continent_code(x)\n",
    "        )\n",
    "\n",
    "        X_new = X_new.drop(\"pais\", axis=1)\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\"score_4\", \"score_7\"]\n",
    "continuous_columns = [\n",
    "    \"score_2\",\n",
    "    \"score_3\",\n",
    "    \"score_5\",\n",
    "    \"score_6\",\n",
    "    \"score_9\",\n",
    "    \"score_10\",\n",
    "    \"valor_compra\",\n",
    "]\n",
    "\n",
    "to_drop_columns = [\"score_fraude_modelo\", \"produto\", \"score_8\"]\n",
    "\n",
    "documents_columns = [\"entrega_doc_1\", \"entrega_doc_2\", \"entrega_doc_3\"]\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"dropper\", DropColumn(to_drop_columns)),\n",
    "        (\n",
    "            \"imputer\",\n",
    "            ImputeValuesProcessor(\n",
    "                discrete_cols=discrete_columns, continuous_cols=continuous_columns\n",
    "            ),\n",
    "        ),\n",
    "        (\"docs\", DocumentsProcessor(documents_columns)),\n",
    "        (\"country\", CountryProcessor()),\n",
    "        (\"date\", DateProcessor()),\n",
    "        (\"encoder\", OneHotEncoderProcessor([\"score_1\", \"continente\"])),\n",
    "        (\"transform\", TransformColumns()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "X_train_t = pipeline.fit_transform(X_train)\n",
    "X_test_t = pipeline.transform(X_test)\n",
    "\n",
    "category_train_df = X_train_t[\"categoria_produto\"].to_frame(name=\"categoria_produto\")\n",
    "category_test_df = X_test_t[\"categoria_produto\"].to_frame(name=\"categoria_produto\")\n",
    "\n",
    "\n",
    "target_encoder = TargetEncoder()\n",
    "\n",
    "X_train_t[\"categoria_produto\"] = target_encoder.fit_transform(\n",
    "    category_train_df, y_train\n",
    ")\n",
    "X_test_t[\"categoria_produto\"] = target_encoder.transform(category_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o preenchimento de valores vazios iremos utilizar a média para variáveis contínuas e a moda para variáveis discretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['score_4', 'score_7', 'score_2', 'score_5', 'score_9', 'score_10'], dtype='object')\n",
      "Index(['score_4', 'score_7', 'score_2', 'score_5', 'score_9', 'score_10'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def convert_to_numeric(df):\n",
    "    new_df = df.copy()\n",
    "    print(new_df.select_dtypes(include=[\"object\"]).columns)\n",
    "    for col in new_df.select_dtypes(include=[\"object\"]).columns:\n",
    "        try:\n",
    "            new_df[col] = pd.to_numeric(new_df[col], errors=\"coerce\")\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "X_train_t = convert_to_numeric(X_train_t)\n",
    "X_test_t = convert_to_numeric(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_4              float64\n",
       "score_7              float64\n",
       "score_2              float64\n",
       "score_5              float64\n",
       "score_9              float64\n",
       "score_10             float64\n",
       "categoria_produto    float64\n",
       "entrega_doc_1          int32\n",
       "entrega_doc_2          int32\n",
       "entrega_doc_3          int32\n",
       "hora_compra            int32\n",
       "dia_compra             int32\n",
       "score_1_2              int32\n",
       "score_1_3              int32\n",
       "score_1_4              int32\n",
       "continente_AS          int32\n",
       "continente_EU          int32\n",
       "continente_NA          int32\n",
       "continente_OC          int32\n",
       "continente_SA          int32\n",
       "log_score_3          float64\n",
       "log_valor_compra     float64\n",
       "cbrt_score_6         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.770848 (0.003251)\n",
      "[0.06894288 0.08440243 0.08024275 0.0704607 ]\n",
      "XGBoost: 0.754982 (0.010100)\n",
      "[0.51411687 0.5172181  0.51449764 0.49728997]\n",
      "[LightGBM] [Info] Number of positive: 4440, number of negative: 85560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 4482, number of negative: 85518\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 4480, number of negative: 85520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 4487, number of negative: 85513\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 4440, number of negative: 85560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 4482, number of negative: 85518\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 4480, number of negative: 85520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 4487, number of negative: 85513\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "LightGBM: 0.787008 (0.004661)\n",
      "[0.64281024 0.65698852 0.63654754 0.6402439 ]\n",
      "Decision Tree: 0.560826 (0.002934)\n",
      "[0.1674327  0.17218096 0.15778827 0.16395664]\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"XGBoost\", XGBClassifier(scale_pos_weight=20, random_state=42)),\n",
    "    (\"LightGBM\", LGBMClassifier(class_weight=\"balanced\", random_state=42)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_t, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "\n",
    "    recall_results = cross_val_score(\n",
    "        model, X_train_t, y_train, cv=kfold, scoring=\"recall\"\n",
    "    )\n",
    "\n",
    "    results.append(cv_results)\n",
    "    msg = \"%s: %f (%f)\" % (\n",
    "        name,\n",
    "        cv_results.mean(),\n",
    "        cv_results.std(),\n",
    "    )\n",
    "    print(msg)\n",
    "    print(recall_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[LightGBM] [Info] Number of positive: 5963, number of negative: 114037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2197\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049692 -> initscore=-2.950949\n",
      "[LightGBM] [Info] Start training from score -2.950949\n",
      "0.7890954478930023\n",
      "Best Parameters: {'subsample': 1.0, 'reg_lambda': 10, 'reg_alpha': 1, 'num_leaves': 50, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 1.0}\n",
      "AUC Score: 0.7940221951675509\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(is_unbalance=True, random_state=42)\n",
    "\n",
    "# Define Hyperparameter Grid\n",
    "param_distributions = {\n",
    "    \"num_leaves\": [31, 50, 70],\n",
    "    \"max_depth\": [-1, 10, 20],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 1, 10],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    # \"scale_pos_weight\": [1, 10, 50],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    scoring=\"roc_auc\",  # Use ROC-AUC as the evaluation metric\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "best_model = random_search.fit(X_train_t, y_train)\n",
    "\n",
    "print(random_search.best_score_)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict_proba(X_test_t)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86     28463\n",
      "           1       0.13      0.67      0.22      1537\n",
      "\n",
      "    accuracy                           0.76     30000\n",
      "   macro avg       0.55      0.72      0.54     30000\n",
      "weighted avg       0.93      0.76      0.82     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer a diferença de métricas pro modelo antigo vs novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict_proba(X_test_t)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33869662, 0.44186255, 0.71116987, ..., 0.16637931, 0.10491473,\n",
       "       0.21172617])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>pais</th>\n",
       "      <th>score_7</th>\n",
       "      <th>produto</th>\n",
       "      <th>categoria_produto</th>\n",
       "      <th>...</th>\n",
       "      <th>score_9</th>\n",
       "      <th>score_10</th>\n",
       "      <th>entrega_doc_1</th>\n",
       "      <th>entrega_doc_2</th>\n",
       "      <th>entrega_doc_3</th>\n",
       "      <th>data_compra</th>\n",
       "      <th>valor_compra</th>\n",
       "      <th>score_fraude_modelo</th>\n",
       "      <th>score_new_model</th>\n",
       "      <th>fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59770</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7643</td>\n",
       "      <td>224172.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>35</td>\n",
       "      <td>Prateleira Aço Refrigerador Continental Rfct47...</td>\n",
       "      <td>cat_dcfa25e</td>\n",
       "      <td>...</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-15 22:24:55</td>\n",
       "      <td>30.11</td>\n",
       "      <td>35</td>\n",
       "      <td>33.869662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21362</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6197</td>\n",
       "      <td>575.78</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>100 Máscaras Descartáveis Prevenção Epidemia C...</td>\n",
       "      <td>cat_604df77</td>\n",
       "      <td>...</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2020-03-19 11:36:11</td>\n",
       "      <td>38.47</td>\n",
       "      <td>90</td>\n",
       "      <td>44.186255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127324</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8011</td>\n",
       "      <td>56806.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.561304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>2</td>\n",
       "      <td>Capinha Capa Silicone C/ Logo iPhone 6s 7 8 Pl...</td>\n",
       "      <td>cat_0820fab</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-04-12 4:47:44</td>\n",
       "      <td>6.02</td>\n",
       "      <td>58</td>\n",
       "      <td>71.116987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140509</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>2163.71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.597080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>3</td>\n",
       "      <td>Azulejo Decorativo Vintage 3 Kits De 9 Peças D...</td>\n",
       "      <td>cat_583f57b</td>\n",
       "      <td>...</td>\n",
       "      <td>2986.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-03-29 14:19:12</td>\n",
       "      <td>13.63</td>\n",
       "      <td>72</td>\n",
       "      <td>16.382614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144297</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>3550.93</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.390681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>12</td>\n",
       "      <td>Patch Troféu Copa Libertadores Da América 2019...</td>\n",
       "      <td>cat_1f924ff</td>\n",
       "      <td>...</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020-03-18 22:27:39</td>\n",
       "      <td>5.98</td>\n",
       "      <td>53</td>\n",
       "      <td>25.541478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        score_1  score_2    score_3  score_4   score_5  score_6 pais  score_7  \\\n",
       "59770         4   0.7643  224172.84      1.0  0.000000     39.0   BR       35   \n",
       "21362         4   0.6197     575.78      2.0  0.000000      0.0   BR        0   \n",
       "127324        4   0.8011   56806.30      2.0  0.561304      0.0   BR        2   \n",
       "140509        4   0.8588    2163.71      3.0  0.597080      0.0   BR        3   \n",
       "144297        4   0.8511    3550.93     16.0  0.390681     23.0   BR       12   \n",
       "\n",
       "                                                  produto categoria_produto  \\\n",
       "59770   Prateleira Aço Refrigerador Continental Rfct47...       cat_dcfa25e   \n",
       "21362   100 Máscaras Descartáveis Prevenção Epidemia C...       cat_604df77   \n",
       "127324  Capinha Capa Silicone C/ Logo iPhone 6s 7 8 Pl...       cat_0820fab   \n",
       "140509  Azulejo Decorativo Vintage 3 Kits De 9 Peças D...       cat_583f57b   \n",
       "144297  Patch Troféu Copa Libertadores Da América 2019...       cat_1f924ff   \n",
       "\n",
       "        ...  score_9  score_10  entrega_doc_1  entrega_doc_2 entrega_doc_3  \\\n",
       "59770   ...   4705.0       0.0              1              N             N   \n",
       "21362   ...   1526.0       0.0              0              N             N   \n",
       "127324  ...   1006.0     129.0              1              Y             Y   \n",
       "140509  ...   2986.0     324.0              1            NaN             Y   \n",
       "144297  ...   1990.0     131.0              1            NaN             Y   \n",
       "\n",
       "                data_compra valor_compra  score_fraude_modelo  \\\n",
       "59770   2020-03-15 22:24:55        30.11                   35   \n",
       "21362   2020-03-19 11:36:11        38.47                   90   \n",
       "127324   2020-04-12 4:47:44         6.02                   58   \n",
       "140509  2020-03-29 14:19:12        13.63                   72   \n",
       "144297  2020-03-18 22:27:39         5.98                   53   \n",
       "\n",
       "        score_new_model  fraude  \n",
       "59770         33.869662       0  \n",
       "21362         44.186255       0  \n",
       "127324        71.116987       0  \n",
       "140509        16.382614       0  \n",
       "144297        25.541478       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new = X_test\n",
    "X_test_new[\"score_new_model\"] = y_pred * 100\n",
    "X_test_new[\"fraude\"] = y_test\n",
    "\n",
    "X_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\renne\\Documents\\Estudos Dados\\Repositórios\\ML\\fraud-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\renne\\anaconda3\\envs\\fraud-detection\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O limiar ótimo encontrado para a amostra é de: 72\n",
      "Ganhos por transações aprovadas: R$ 80329.99\n",
      "Prejuízos com transações fraudulentas aprovadas: R$ 25353.32\n",
      "Receita gerada com limiar ótimo: R$ 54976.67\n",
      "Taxa de pressão de entrada é de 5.123333333333333%\n",
      "Taxa de aprovação total é de 73.37%\n",
      "Taxa de declínio total é de 25.66%\n",
      "A precisão do modelo é de 13.43%\n",
      "A precisão do modelo é de 68.21%\n",
      "A taxa de falsos positivos é de 23.64%\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "from src.features.base_metrics import BaseMetrics\n",
    "\n",
    "\n",
    "bm_1 = BaseMetrics(X_test_new, \"score_fraude_modelo\", \"fraude\", \"valor_compra\")\n",
    "\n",
    "bm_1.find_best_threshold()\n",
    "bm_1.show_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O limiar ótimo encontrado para a amostra é de: 63\n",
      "Ganhos por transações aprovadas: R$ 93952.96\n",
      "Prejuízos com transações fraudulentas aprovadas: R$ 32723.68\n",
      "Receita gerada com limiar ótimo: R$ 61229.28\n",
      "Taxa de pressão de entrada é de 5.123333333333333%\n",
      "Taxa de aprovação total é de 64.43%\n",
      "Taxa de declínio total é de 34.60%\n",
      "A precisão do modelo é de 19.79%\n",
      "A precisão do modelo é de 49.77%\n",
      "A taxa de falsos positivos é de 10.89%\n"
     ]
    }
   ],
   "source": [
    "bm_1 = BaseMetrics(X_test_new, \"score_new_model\", \"fraude\", \"valor_compra\")\n",
    "\n",
    "bm_1.find_best_threshold()\n",
    "bm_1.show_all_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
